{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import georinex as gr\n",
    "import numpy as np\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize logging\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System dependencies\n",
    "- install georinex, pandas, numpy, sklearn, yaml, and jupyter as python packages\n",
    "- install dvc as a system package\n",
    "- git clone this repo\n",
    "- to enable the python-app.yml github action, use your github settings page and enable the workflow manually. This will allow you to train a new model with every commit to the `main` branch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Below we prepare the data as a np.array for both the `nav_df` and the `labels`. This can almost certainly be improved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\tools\\Anaconda3\\envs\\survey\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "nav_file = '../2021.09.17_jamming/parsed-rinex/COM37_210917_110602_jamming.nav'\n",
    "obs_file = '../2021.09.17_jamming/parsed-rinex/COM37_210917_110602_jamming.obs'\n",
    "obs = gr.load(obs_file)\n",
    "nav = gr.load(nav_file)\n",
    "hdr_obs = gr.rinexheader(obs_file)\n",
    "hdr_nav = gr.rinexheader(nav_file)\n",
    "obs_df = obs.to_dataframe()\n",
    "obs_df.fillna(value = 0, axis = 1)\n",
    "obs_df = obs_df.sort_index()\n",
    "labels = np.zeros(len(obs_df))\n",
    "tmp = int(12350/5)\n",
    "tmp2 = tmp * 2\n",
    "labels[tmp2: tmp2+tmp] = np.ones(tmp)\n",
    "assert set(labels) == set([0,1])\n",
    "obs_df = np.nan_to_num(obs_df)\n",
    "\n",
    "## This code snippet is inside the data.py file, accessible by calling Data(dataset= 'rinex-obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "specified in configs/prepare.yml and can be changed by command line or function arguments. Supports datasets outlined in data.py as well as arbitrary csvs, assuming the last column is the target vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Training\n",
    "\n",
    "because each layer performs a grid search on the best hyper-parameter and object combination specified in the .yml file, we need to train an initial model so that we can make objective measurements as we add more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "specified in `configs/preprocess.yml` and can be changed with command-line or functional arguments. Supports any sklearn preprocessor from [this documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing). Below we declare the paths for our configuration file and results folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Featurizing\n",
    "\n",
    "specified in `configs/preprocess.yml` and can be changed with command-line or functional arguments. Supports any sklearn preprocessor from [this documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing). Below we declare the paths for our configuration file and results folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the data\n",
    "TODO:\n",
    "Once we know what our best model is, we can use it to predict on a new set of data using the evaluate.py script. Parameters for scoring can be specified in evaluate.yml. Please note that metrics that require parameters other than `y_test` or `y_pred` at runtime must first be made into a scorer callable using the sklearn make_scorer() function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVC\n",
    "\n",
    "This repo uses a dvc pipeline to store the data pipeline in a git repository. You can see the pipeline in `dvc.yaml` which specifies input and output params for each layer, as well as what script to run. After performing any edits run: ```dvc repro``` to reproduce the experiment. Please note it will only re-run pipeline components that have not changed, so it is imperative that all dependencies are explicit. When that is done, view the metrics with ```dvc metrics show```. You can also generate plots automatically or from the command line with ```dvc plots modify```. You can run the commands from inside a jupyter notebook by preprending system commands with a '!' as demonstated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  +---------+  \n",
      "  | prepare |  \n",
      "  +---------+  \n",
      "       *       \n",
      "       *       \n",
      "       *       \n",
      "  +-------+    \n",
      "  | train |    \n",
      "  +-------+    \n",
      "       *       \n",
      "       *       \n",
      "       *       \n",
      "+------------+ \n",
      "| preprocess | \n",
      "+------------+ \n",
      "       *       \n",
      "       *       \n",
      "       *       \n",
      "+-----------+  \n",
      "| featurize |  \n",
      "+-----------+  \n"
     ]
    }
   ],
   "source": [
    " # shows the dag of the pipeline\n",
    "!dvc dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# reproduces the pipeline on your local machine\n",
    "!dvc repro > repro.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                               Metric             HEAD        workspace      Change\n",
      "data\\best_preprocess\\results.json  Accuracy           0.95337     0.80246        -0.15091\n",
      "data\\best_preprocess\\results.json  Balanced Accuracy  0.88618     0.51534        -0.37084\n",
      "data\\best_preprocess\\results.json  F1                 0.9512      0.72148        -0.22972\n",
      "data\\best_preprocess\\results.json  Precision          0.95483     0.81568        -0.13915\n",
      "data\\best_preprocess\\results.json  Recall             0.95337     0.80246        -0.15091\n",
      "data\\best_preprocess\\results.json  fit_time           703125000   1177656250000  1176953125000\n",
      "data\\best_preprocess\\results.json  pred_time          31250000    859375000      828125000\n",
      "data\\best_train\\results.json       Accuracy           0.95758     0.79696        -0.16062\n",
      "data\\best_train\\results.json       Balanced Accuracy  0.89254     0.5            -0.39254\n",
      "data\\best_train\\results.json       F1                 0.95559     0.70691        -0.24868\n",
      "data\\best_train\\results.json       Precision          0.95957     0.63514        -0.32443\n",
      "data\\best_train\\results.json       Recall             0.95758     0.79696        -0.16062\n",
      "data\\best_train\\results.json       fit_time           1937500000  827859375000   825921875000\n",
      "data\\best_train\\results.json       pred_time          78125000    1843750000     1765625000\n",
      "data\\best_features\\results.json    Accuracy           0.95337     0.80246        -0.15091\n",
      "data\\best_features\\results.json    Balanced Accuracy  0.88618     0.51534        -0.37084\n",
      "data\\best_features\\results.json    F1                 0.9512      0.72148        -0.22972\n",
      "data\\best_features\\results.json    Precision          0.95483     0.81568        -0.13915\n",
      "data\\best_features\\results.json    Recall             0.95337     0.80246        -0.15091\n",
      "data\\best_features\\results.json    fit_time           468750000   1169656250000  1169187500000\n",
      "data\\best_features\\results.json    pred_time          31250000    1031250000     1000000000\n"
     ]
    }
   ],
   "source": [
    "# Displays the metrics specified in the experiment object, set by (TODO) `evaluate.py`\n",
    "! dvc metrics diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9daac9ed69900a4a309ec6040543edec71586376af7854d65a0f277dfb55f14b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
